{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Export\n",
    "\n",
    "In this notebook, I train and export a model to identify dog breeds from photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Getting the data here is easy, since I did all of the hard work in the data processing script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I load in the label vocabulary from a saved numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = np.load('data/labelvocab.npy')\n",
    "n_classes = np.shape(label_vocab)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, I load in the basis for the transfer learning model so I can get its input size. I'm using the one of the pre-trained MobileNet V2 models from Tensorflow Hub because it works very well on limited resources, so I won't need anything fancy (or expensive) to serve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'.\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2'.\n"
     ]
    }
   ],
   "source": [
    "image_col = hub.image_embedding_column(\"image\", \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/2\")\n",
    "\n",
    "height, width = hub.get_expected_image_size(image_col.module_spec)\n",
    "depth = hub.get_num_image_channels(image_col.module_spec)\n",
    "size = (height, width, depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input function here is pretty straightforward. it just loads the TFRecords at the given filename, decodes them, shuffles them, and batches them. The function returns a lambda function so I can make versions for both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_fn(fname, repeat=1, batch_size=256):\n",
    "    ds = (tf.data.TFRecordDataset(fname)\n",
    "          .map(lambda im: \n",
    "               utils.decode_image_example(im, size))\n",
    "          .shuffle(batch_size*2) # arbitrary\n",
    "          .repeat(repeat)\n",
    "          .batch(batch_size)\n",
    "          .prefetch(2))\n",
    "    \n",
    "    return lambda: ds.make_one_shot_iterator().get_next()\n",
    "\n",
    "train_input_fn = make_input_fn('data/dogs224_train.tfrecord', 3)\n",
    "valid_input_fn = make_input_fn('data/dogs224_valid.tfrecord')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Here's the fun (and slow part): training the model. Keeping with my theme of simplicity, I train a canned linear classifier that consumes the output of MobileNet and outputs a prediction in terms of our labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpwppe1d9r\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpwppe1d9r', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fe7515dc1d0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "est = tf.estimator.LinearClassifier(\n",
    "    [image_col],\n",
    "    n_classes=n_classes,\n",
    "    label_vocabulary=list(label_vocab)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I turn down log verbosity here because TF Hub modules produce a monumental amount of log spam when they first load in. I also periodically print evaluation metrics from the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8022352, 'average_loss': 1.9217477, 'loss': 439.43964, 'global_step': 96}\n",
      "{'accuracy': 0.8070943, 'average_loss': 1.7060735, 'loss': 390.12216, 'global_step': 192}\n",
      "{'accuracy': 0.81341106, 'average_loss': 1.6882304, 'loss': 386.04202, 'global_step': 288}\n",
      "{'accuracy': 0.81341106, 'average_loss': 1.680952, 'loss': 384.3777, 'global_step': 384}\n",
      "{'accuracy': 0.8158406, 'average_loss': 1.6717596, 'loss': 382.2757, 'global_step': 480}\n"
     ]
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "for _ in range(5):\n",
    "    est.train(train_input_fn)\n",
    "    print(est.evaluate(valid_input_fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My serving input function takes in a vector (of unknown length) of strings that represent encoded images. They're then preprocessed and resized in the same manner as the training data (with the same function) before being sent to the model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def serving_input_fn():\n",
    "    receiver = tf.placeholder(tf.string, shape=(None))\n",
    "    examples = tf.parse_example(\n",
    "        receiver,\n",
    "        {\n",
    "            \"image\": tf.FixedLenFeature((), tf.string),\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    \n",
    "    decode_and_prep = lambda image: utils.preprocess_image(image, size[:-1])\n",
    "    \n",
    "    images = tf.map_fn(decode_and_prep, examples[\"image\"],\n",
    "                       tf.float32)\n",
    "    \n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        {\"image\": images},\n",
    "        receiver,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'serving/model/1530162989'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "est.export_savedmodel(\"serving/model/\", serving_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
